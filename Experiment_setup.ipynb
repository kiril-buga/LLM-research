{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T15:12:26.198882Z",
     "start_time": "2025-05-02T15:12:24.079561Z"
    }
   },
   "source": [
    "from langchain.prompts import Prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from function_registry import FunctionRegistry\n",
    "import os\n",
    "from langchain_cerebras import ChatCerebras\n",
    "from dotenv import load_dotenv\n",
    "# Set up the environment\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatCerebras(\n",
    "    model=\"llama-3.3-70b\",\n",
    "    api_key=os.getenv(\"CEREBRAS_API_KEY\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:12:26.361232Z",
     "start_time": "2025-05-02T15:12:26.345441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from parser import GoogleParser\n",
    "import ai_functions  # Important for registering functions\n",
    "\n",
    "registry = FunctionRegistry(docstring_parser=GoogleParser())\n",
    "registry.register_decorated_functions()\n",
    "tools = registry.get_tools()\n",
    "print(f\"Tools: {tools}\")\n",
    "print(f\"Registered {len(tools)} tools\")"
   ],
   "id": "ba3ebe6def91dc6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools: []\n",
      "Registered 0 tools\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:12:26.403556Z",
     "start_time": "2025-05-02T15:12:26.373699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is a workaround to get the function signature\n",
    "from langchain.tools import Tool\n",
    "from pydantic import BaseModel, Field\n",
    "from functools import partial\n",
    "\n",
    "# Tools in LangChain-Format bringen\n",
    "def make_tool_wrapper(fn_name):\n",
    "    def _run(*args, **kwargs):\n",
    "        # Positional Dict -> kwargs\n",
    "        if args and isinstance(args[0], dict):\n",
    "            kwargs = args[0]\n",
    "        return registry.call_function(fn_name, **kwargs)\n",
    "\n",
    "    return _run\n",
    "\n",
    "\n",
    "# lc_tools = []\n",
    "# for tool_spec in tools:\n",
    "#     name = tool_spec[\"function\"][\"name\"]\n",
    "#     description = tool_spec[\"function\"][\"description\"]\n",
    "#     fn = lambda **kwargs: registry.call_function(name, **kwargs)  # Achtung: capture!\n",
    "#     lc_tools.append(\n",
    "#         Tool.from_function(\n",
    "#             name=name,\n",
    "#             description=description,\n",
    "#             func=fn\n",
    "#         )\n",
    "#     )\n",
    "# Generates SQL queries and returns them as a string\n",
    "class ResponseFormatter(BaseModel):\n",
    "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
    "    answer: str = Field(description=\"The answer to the user's question\")\n",
    "    sql_query: str = Field(description=\"SQl query to get the answer\")"
   ],
   "id": "610ca32ab7a44b24",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:12:28.537974Z",
     "start_time": "2025-05-02T15:12:26.424264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ai_functions import calculate_m2_for_asset_components\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "query = \"Wie gross ist die Fensterfl채che im 2. Obergeschoss?\"\n",
    "# agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "# response = agent.invoke(\"Wie gross ist die Fensterfl채che im 2. Obergeschoss?\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"You are a helpful facility management assistant. Your task is to answer questions about the facility.\"),\n",
    "        # Placeholders fill up a **list** of messages\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "tools = [ResponseFormatter, calculate_m2_for_asset_components, ]\n",
    "# langgraph_agent_executor = create_react_agent(llm, tools, prompt=prompt)\n",
    "# messages = langgraph_agent_executor.invoke(\n",
    "#     {\"messages\": [(\"user\", query)]},\n",
    "# )\n",
    "# print(messages[\"messages\"][-1])\n",
    "\n",
    "model_with_tools = llm.bind_tools(tools, tool_choice='required')\n",
    "print(model_with_tools.invoke(query))\n",
    "\n"
   ],
   "id": "1b6826c90e9bc9ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': '49d2c5bec', 'function': {'arguments': '{\"answer\": \"Die Fensterfl\\\\u00e4che im 2. Obergeschoss kann nicht direkt berechnet werden, ohne die genauen Abmessungen der Fenster zu kennen. Allerdings kann die Funktion calculate_m2_for_asset_components verwendet werden, um die Gesamtfl\\\\u00e4che der Fenster in diesem Bereich zu berechnen.\", \"sql_query\": \"SELECT * FROM asset_components WHERE floor = \\'2. Obergeschoss\\' AND type = \\'IfcWindow\\'\"}', 'name': 'ResponseFormatter'}, 'type': 'function'}, {'id': 'c7223e0cb', 'function': {'arguments': '{\"asset_component_type\": \"IfcWindow\", \"floor\": \"2. Obergeschoss\"}', 'name': 'calculate_m2_for_asset_components'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 121, 'prompt_tokens': 407, 'total_tokens': 528, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama-3.3-70b', 'system_fingerprint': 'fp_4a36a9b9a8b8ef701032', 'id': 'chatcmpl-3b1a37f1-f8e1-4196-9d0e-9cc75df5c21f', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-336f1318-71fb-4d51-ad7d-f59b6405cd8d-0' tool_calls=[{'name': 'ResponseFormatter', 'args': {'answer': 'Die Fensterfl채che im 2. Obergeschoss kann nicht direkt berechnet werden, ohne die genauen Abmessungen der Fenster zu kennen. Allerdings kann die Funktion calculate_m2_for_asset_components verwendet werden, um die Gesamtfl채che der Fenster in diesem Bereich zu berechnen.', 'sql_query': \"SELECT * FROM asset_components WHERE floor = '2. Obergeschoss' AND type = 'IfcWindow'\"}, 'id': '49d2c5bec', 'type': 'tool_call'}, {'name': 'calculate_m2_for_asset_components', 'args': {'asset_component_type': 'IfcWindow', 'floor': '2. Obergeschoss'}, 'id': 'c7223e0cb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 407, 'output_tokens': 121, 'total_tokens': 528, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:12:28.580338Z",
     "start_time": "2025-05-02T15:12:28.576728Z"
    }
   },
   "cell_type": "code",
   "source": "model_with_tools = llm.bind_tools([ResponseFormatter])",
   "id": "7364e5472ad5d744",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:12:28.985474Z",
     "start_time": "2025-05-02T15:12:28.596201Z"
    }
   },
   "cell_type": "code",
   "source": "model_with_tools.invoke(\"How wide are windows in the Facility #3?\")",
   "id": "2db77fe875fb585c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have specific information about the width of windows in Facility #3, as there is no context provided about what Facility #3 refers to. If you could provide more details or clarify the location or purpose of Facility #3, I might be able to offer more relevant information or guidance on where to find the answer.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 278, 'total_tokens': 348, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama-3.3-70b', 'system_fingerprint': 'fp_c1b1963fdfa747d6bac1', 'id': 'chatcmpl-10635a3a-091e-4a1b-b3ed-ccdf251e6536', 'finish_reason': 'stop', 'logprobs': None}, id='run-525042da-7154-4107-a501-b7a0eef857aa-0', usage_metadata={'input_tokens': 278, 'output_tokens': 70, 'total_tokens': 348, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
